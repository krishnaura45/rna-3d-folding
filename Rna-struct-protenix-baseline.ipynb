{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd8f83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:27.350921Z",
     "iopub.status.busy": "2025-04-07T10:39:27.350524Z",
     "iopub.status.idle": "2025-04-07T10:39:27.355384Z",
     "shell.execute_reply": "2025-04-07T10:39:27.354581Z"
    },
    "papermill": {
     "duration": 0.010885,
     "end_time": "2025-04-07T10:39:27.356551",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.345666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='protenix'\n",
    "VALIDATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313845b",
   "metadata": {
    "papermill": {
     "duration": 0.002565,
     "end_time": "2025-04-07T10:39:27.362240",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.359675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead40e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:27.368169Z",
     "iopub.status.busy": "2025-04-07T10:39:27.367934Z",
     "iopub.status.idle": "2025-04-07T10:39:27.484868Z",
     "shell.execute_reply": "2025-04-07T10:39:27.483655Z"
    },
    "papermill": {
     "duration": 0.121786,
     "end_time": "2025-04-07T10:39:27.486604",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.364818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    !pip install --no-deps protenix\n",
    "    !pip install biopython\n",
    "    !pip install ml-collections\n",
    "    !pip install biotite==1.0.1\n",
    "    !pip install rdkit\n",
    "!export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaba905b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:27.493345Z",
     "iopub.status.busy": "2025-04-07T10:39:27.493081Z",
     "iopub.status.idle": "2025-04-07T10:39:27.870395Z",
     "shell.execute_reply": "2025-04-07T10:39:27.869372Z"
    },
    "papermill": {
     "duration": 0.382312,
     "end_time": "2025-04-07T10:39:27.871974",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.489662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.v20240608.cif\t\tmodel_v0.2.0.pt\r\n",
      "components.v20240608.cif.rdkit_mol.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir /af3-dev \n",
    "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
    "! ls /af3-dev/release_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d011d0",
   "metadata": {
    "papermill": {
     "duration": 0.002592,
     "end_time": "2025-04-07T10:39:27.877789",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.875197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1291184a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:27.884184Z",
     "iopub.status.busy": "2025-04-07T10:39:27.883898Z",
     "iopub.status.idle": "2025-04-07T10:39:32.012971Z",
     "shell.execute_reply": "2025-04-07T10:39:32.011845Z"
    },
    "papermill": {
     "duration": 4.13409,
     "end_time": "2025-04-07T10:39:32.014597",
     "exception": false,
     "start_time": "2025-04-07T10:39:27.880507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT OK !!!!\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
    "from Bio import SeqIO\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "time0=time.time()\n",
    "\n",
    "print('IMPORT OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96fcada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:32.021761Z",
     "iopub.status.busy": "2025-04-07T10:39:32.021360Z",
     "iopub.status.idle": "2025-04-07T10:39:32.143662Z",
     "shell.execute_reply": "2025-04-07T10:39:32.142819Z"
    },
    "papermill": {
     "duration": 0.127307,
     "end_time": "2025-04-07T10:39:32.145025",
     "exception": false,
     "start_time": "2025-04-07T10:39:32.017718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON /usr/bin/python3\n",
      "HELPER OK!!!\n"
     ]
    }
   ],
   "source": [
    "PYTHON = sys.executable\n",
    "print('PYTHON',PYTHON)\n",
    "\n",
    "RHONET_DIR=\\\n",
    "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
    "#'<your downloaded rhofold repo>/RhoFold-main'\n",
    "\n",
    "USALIGN = \\\n",
    "'/kaggle/working//USalign'\n",
    "#'<your us align path>/USalign'\n",
    "\n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
    "sys.path.append(RHONET_DIR)\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "\n",
    "# helper ----\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "# visualisation helper ----\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xyz df helper --------------------\n",
    "def get_truth_df(target_id):\n",
    "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_output_to_df(output, seq, target_id):\n",
    "    df = []\n",
    "    chain_data = []\n",
    "    for i, res in enumerate(seq):\n",
    "        d=dict(ID = target_id,\n",
    "                    resname=res,\n",
    "                    resid=i+1)\n",
    "        for n in range(len(output)):\n",
    "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
    "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
    "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
    "        chain_data.append(d)\n",
    "\n",
    "    if len(chain_data)!=0:\n",
    "        chain_df = pd.DataFrame(chain_data)\n",
    "        df.append(chain_df)\n",
    "        ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "def parse_pdb_to_df(pdb_file, target_id):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('', pdb_file)\n",
    "\n",
    "    df = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            print(chain)\n",
    "            chain_data = []\n",
    "            for residue in chain:\n",
    "                # print(residue)\n",
    "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
    "                    # Check if the residue has a C1' atom\n",
    "                    if 'C1\\'' in residue:\n",
    "                        atom = residue['C1\\'']\n",
    "                        xyz = atom.get_coord()\n",
    "                        resname = residue.get_resname()\n",
    "                        resid = residue.get_id()[1]\n",
    "\n",
    "                        #todo detect discontinous: resid = prev_resid+1\n",
    "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
    "                        chain_data.append(dict(\n",
    "                            ID = target_id+'_'+str(resid),\n",
    "                            resname=resname,\n",
    "                            resid=resid,\n",
    "                            x_1=xyz[0],\n",
    "                            y_1=xyz[1],\n",
    "                            z_1=xyz[2],\n",
    "                        ))\n",
    "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
    "\n",
    "            if len(chain_data)!=0:\n",
    "                chain_df = pd.DataFrame(chain_data)\n",
    "                df.append(chain_df)\n",
    "                ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "# usalign helper --------------------\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes a single line of PDB format based on provided atom information.\n",
    "\n",
    "    Args:\n",
    "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
    "        atom_serial (int): Atom serial number.\n",
    "        residue_name (str): Residue name (e.g., \"ALA\").\n",
    "        chain_id (str): Chain identifier.\n",
    "        residue_num (int): Residue number.\n",
    "        x_coord (float): X coordinate.\n",
    "        y_coord (float): Y coordinate.\n",
    "        z_coord (float): Z coordinate.\n",
    "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
    "        b_factor (float, optional): B-factor value (default: 0.0).\n",
    "\n",
    "    Returns:\n",
    "        str: A single line of PDB string.\n",
    "    \"\"\"\n",
    "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "\n",
    "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
    "    resolved_cnt = 0\n",
    "    with open(pdb_file, 'w') as target_file:\n",
    "        for _, row in df.iterrows():\n",
    "            x_coord = row[f'x_{xyz_id}']\n",
    "            y_coord = row[f'y_{xyz_id}']\n",
    "            z_coord = row[f'z_{xyz_id}']\n",
    "\n",
    "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                target_line = write_target_line(\n",
    "                    atom_name=\"C1'\",\n",
    "                    atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'],\n",
    "                    chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x_coord,\n",
    "                    y_coord=y_coord,\n",
    "                    z_coord=z_coord,\n",
    "                    atom_type='C',\n",
    "                )\n",
    "                target_file.write(target_line)\n",
    "    return resolved_cnt\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "def call_usalign(predict_df, truth_df, verbose=1):\n",
    "    truth_pdb = '~truth.pdb'\n",
    "    predict_pdb = '~predict.pdb'\n",
    "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
    "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
    "\n",
    "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "    output = os.popen(command).read()\n",
    "    if verbose==1:\n",
    "        print(output)\n",
    "    tm_score = parse_usalign_for_tm_score(output)\n",
    "    transform = parse_usalign_for_transform(output)\n",
    "    return tm_score, transform\n",
    "\n",
    "print('HELPER OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cdcd5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:32.151810Z",
     "iopub.status.busy": "2025-04-07T10:39:32.151566Z",
     "iopub.status.idle": "2025-04-07T10:39:36.953850Z",
     "shell.execute_reply": "2025-04-07T10:39:36.953099Z"
    },
    "papermill": {
     "duration": 4.807223,
     "end_time": "2025-04-07T10:39:36.955389",
     "exception": false,
     "start_time": "2025-04-07T10:39:32.148166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "    \n",
    "    \n",
    "    from runner.batch_inference import get_default_runner\n",
    "    from runner.inference import update_inference_configs, InferenceRunner\n",
    "\n",
    "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.random.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    class DictDataset(InferenceDataset):\n",
    "        def __init__(\n",
    "            self,\n",
    "            seq_list: list,\n",
    "            dump_dir: str,\n",
    "            id_list: list = None,\n",
    "            use_msa: bool = False,\n",
    "        ) -> None:\n",
    "\n",
    "            self.dump_dir = dump_dir\n",
    "            self.use_msa = use_msa\n",
    "            if isinstance(id_list,type(None)):\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": \"query\"} for seq in seq_list]\n",
    "            else:\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": i} for i, seq in zip(id_list,seq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5f2fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:36.962970Z",
     "iopub.status.busy": "2025-04-07T10:39:36.962451Z",
     "iopub.status.idle": "2025-04-07T10:39:54.804330Z",
     "shell.execute_reply": "2025-04-07T10:39:54.803603Z"
    },
    "papermill": {
     "duration": 17.847181,
     "end_time": "2025-04-07T10:39:54.805920",
     "exception": false,
     "start_time": "2025-04-07T10:39:36.958739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "\n",
    "    from configs.configs_base import configs as configs_base\n",
    "    from configs.configs_data import data_configs\n",
    "    from configs.configs_inference import inference_configs\n",
    "    from protenix.config.config import parse_configs\n",
    "\n",
    "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
    "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
    "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
    "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 5)\n",
    "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
    "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
    "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
    "\n",
    "    configs = parse_configs(\n",
    "            configs=configs,\n",
    "            fill_required_with_null=True,\n",
    "        )\n",
    "    \n",
    "    runner=InferenceRunner(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c25d3ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:54.813531Z",
     "iopub.status.busy": "2025-04-07T10:39:54.813278Z",
     "iopub.status.idle": "2025-04-07T10:39:54.816928Z",
     "shell.execute_reply": "2025-04-07T10:39:54.816290Z"
    },
    "papermill": {
     "duration": 0.008635,
     "end_time": "2025-04-07T10:39:54.818021",
     "exception": false,
     "start_time": "2025-04-07T10:39:54.809386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
    "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545dc749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:54.824919Z",
     "iopub.status.busy": "2025-04-07T10:39:54.824707Z",
     "iopub.status.idle": "2025-04-07T10:39:54.831041Z",
     "shell.execute_reply": "2025-04-07T10:39:54.830426Z"
    },
    "papermill": {
     "duration": 0.011096,
     "end_time": "2025-04-07T10:39:54.832261",
     "exception": false,
     "start_time": "2025-04-07T10:39:54.821165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    train_df['protenix_tm_score']=None\n",
    "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
    "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
    "            continue\n",
    "        if len(seq)>300:\n",
    "            continue\n",
    "        target_id = train_df.loc[i,'target_id']\n",
    "        truth_df = get_truth_df(target_id)\n",
    "        if sum(~np.isnan(truth_df.x_1))<3:\n",
    "            continue\n",
    "        data, atom_array, data_error_message=dataset[i]\n",
    "        if data_error_message!='':\n",
    "            continue\n",
    "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "        runner.update_model_configs(new_configs)\n",
    "        prediction = runner.predict(data)\n",
    "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]       \n",
    "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
    "        try:\n",
    "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
    "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
    "        except:\n",
    "            pass\n",
    "        if (time.time()-time0)>(12*3600-360):\n",
    "            break\n",
    "    train_df.to_csv('tm_scores.csv', index=False)\n",
    "    print(train_df.protenix_tm_score.mean())\n",
    "    display(train_df.protenix_tm_score.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c68408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T10:39:54.838726Z",
     "iopub.status.busy": "2025-04-07T10:39:54.838525Z",
     "iopub.status.idle": "2025-04-07T11:14:52.345002Z",
     "shell.execute_reply": "2025-04-07T11:14:52.344162Z"
    },
    "papermill": {
     "duration": 2097.51126,
     "end_time": "2025-04-07T11:14:52.346439",
     "exception": false,
     "start_time": "2025-04-07T10:39:54.835179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [34:57<00:00, 174.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.730</td>\n",
       "      <td>-1.294</td>\n",
       "      <td>-8.305</td>\n",
       "      <td>-3.912</td>\n",
       "      <td>11.760</td>\n",
       "      <td>6.376</td>\n",
       "      <td>-5.031</td>\n",
       "      <td>-13.139</td>\n",
       "      <td>-5.074</td>\n",
       "      <td>2.312</td>\n",
       "      <td>15.456</td>\n",
       "      <td>8.403</td>\n",
       "      <td>-2.367</td>\n",
       "      <td>-17.717</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.161</td>\n",
       "      <td>-4.587</td>\n",
       "      <td>-5.077</td>\n",
       "      <td>-8.980</td>\n",
       "      <td>9.421</td>\n",
       "      <td>7.629</td>\n",
       "      <td>-9.351</td>\n",
       "      <td>-11.113</td>\n",
       "      <td>-8.446</td>\n",
       "      <td>-3.401</td>\n",
       "      <td>16.060</td>\n",
       "      <td>8.049</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-19.747</td>\n",
       "      <td>-3.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.744</td>\n",
       "      <td>-8.994</td>\n",
       "      <td>-3.519</td>\n",
       "      <td>-13.971</td>\n",
       "      <td>7.201</td>\n",
       "      <td>6.020</td>\n",
       "      <td>-14.140</td>\n",
       "      <td>-7.897</td>\n",
       "      <td>-9.102</td>\n",
       "      <td>-8.314</td>\n",
       "      <td>15.961</td>\n",
       "      <td>4.945</td>\n",
       "      <td>2.156</td>\n",
       "      <td>-18.635</td>\n",
       "      <td>-9.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.045</td>\n",
       "      <td>-13.868</td>\n",
       "      <td>-5.033</td>\n",
       "      <td>-17.469</td>\n",
       "      <td>5.158</td>\n",
       "      <td>2.058</td>\n",
       "      <td>-17.739</td>\n",
       "      <td>-4.134</td>\n",
       "      <td>-7.138</td>\n",
       "      <td>-11.188</td>\n",
       "      <td>14.593</td>\n",
       "      <td>0.227</td>\n",
       "      <td>2.800</td>\n",
       "      <td>-15.249</td>\n",
       "      <td>-13.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.999</td>\n",
       "      <td>-17.148</td>\n",
       "      <td>-9.435</td>\n",
       "      <td>-18.713</td>\n",
       "      <td>3.172</td>\n",
       "      <td>-2.961</td>\n",
       "      <td>-19.661</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>-3.601</td>\n",
       "      <td>-11.864</td>\n",
       "      <td>12.004</td>\n",
       "      <td>-4.735</td>\n",
       "      <td>2.717</td>\n",
       "      <td>-10.547</td>\n",
       "      <td>-16.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>16.224</td>\n",
       "      <td>-1.435</td>\n",
       "      <td>6.071</td>\n",
       "      <td>14.659</td>\n",
       "      <td>-9.997</td>\n",
       "      <td>8.910</td>\n",
       "      <td>10.001</td>\n",
       "      <td>-16.855</td>\n",
       "      <td>-5.087</td>\n",
       "      <td>-23.179</td>\n",
       "      <td>5.137</td>\n",
       "      <td>3.816</td>\n",
       "      <td>12.927</td>\n",
       "      <td>14.884</td>\n",
       "      <td>-4.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>11.572</td>\n",
       "      <td>-3.535</td>\n",
       "      <td>5.830</td>\n",
       "      <td>12.975</td>\n",
       "      <td>-14.573</td>\n",
       "      <td>7.152</td>\n",
       "      <td>11.501</td>\n",
       "      <td>-13.710</td>\n",
       "      <td>-1.268</td>\n",
       "      <td>-20.021</td>\n",
       "      <td>1.492</td>\n",
       "      <td>5.614</td>\n",
       "      <td>17.683</td>\n",
       "      <td>16.285</td>\n",
       "      <td>-6.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>7.624</td>\n",
       "      <td>-7.213</td>\n",
       "      <td>6.402</td>\n",
       "      <td>13.323</td>\n",
       "      <td>-19.729</td>\n",
       "      <td>5.112</td>\n",
       "      <td>12.052</td>\n",
       "      <td>-11.651</td>\n",
       "      <td>3.931</td>\n",
       "      <td>-16.441</td>\n",
       "      <td>-2.545</td>\n",
       "      <td>5.464</td>\n",
       "      <td>21.966</td>\n",
       "      <td>19.185</td>\n",
       "      <td>-8.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>5.030</td>\n",
       "      <td>-11.155</td>\n",
       "      <td>8.936</td>\n",
       "      <td>15.770</td>\n",
       "      <td>-24.653</td>\n",
       "      <td>4.880</td>\n",
       "      <td>12.728</td>\n",
       "      <td>-12.196</td>\n",
       "      <td>9.347</td>\n",
       "      <td>-12.248</td>\n",
       "      <td>-5.109</td>\n",
       "      <td>3.308</td>\n",
       "      <td>24.553</td>\n",
       "      <td>23.874</td>\n",
       "      <td>-9.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>4.257</td>\n",
       "      <td>-13.530</td>\n",
       "      <td>13.472</td>\n",
       "      <td>18.974</td>\n",
       "      <td>-27.890</td>\n",
       "      <td>7.465</td>\n",
       "      <td>14.003</td>\n",
       "      <td>-15.435</td>\n",
       "      <td>13.286</td>\n",
       "      <td>-7.952</td>\n",
       "      <td>-4.612</td>\n",
       "      <td>0.382</td>\n",
       "      <td>24.867</td>\n",
       "      <td>28.885</td>\n",
       "      <td>-8.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid     x_1     y_1     z_1     x_2     y_2    z_2  \\\n",
       "0       R1107_1       G      1 -16.730  -1.294  -8.305  -3.912  11.760  6.376   \n",
       "1       R1107_2       G      2 -13.161  -4.587  -5.077  -8.980   9.421  7.629   \n",
       "2       R1107_3       G      3  -9.744  -8.994  -3.519 -13.971   7.201  6.020   \n",
       "3       R1107_4       G      4  -7.045 -13.868  -5.033 -17.469   5.158  2.058   \n",
       "4       R1107_5       G      5  -4.999 -17.148  -9.435 -18.713   3.172 -2.961   \n",
       "...         ...     ...    ...     ...     ...     ...     ...     ...    ...   \n",
       "2510  R1190_114       U    114  16.224  -1.435   6.071  14.659  -9.997  8.910   \n",
       "2511  R1190_115       U    115  11.572  -3.535   5.830  12.975 -14.573  7.152   \n",
       "2512  R1190_116       U    116   7.624  -7.213   6.402  13.323 -19.729  5.112   \n",
       "2513  R1190_117       U    117   5.030 -11.155   8.936  15.770 -24.653  4.880   \n",
       "2514  R1190_118       U    118   4.257 -13.530  13.472  18.974 -27.890  7.465   \n",
       "\n",
       "         x_3     y_3     z_3     x_4     y_4    z_4     x_5     y_5     z_5  \n",
       "0     -5.031 -13.139  -5.074   2.312  15.456  8.403  -2.367 -17.717   0.867  \n",
       "1     -9.351 -11.113  -8.446  -3.401  16.060  8.049   0.337 -19.747  -3.712  \n",
       "2    -14.140  -7.897  -9.102  -8.314  15.961  4.945   2.156 -18.635  -9.108  \n",
       "3    -17.739  -4.134  -7.138 -11.188  14.593  0.227   2.800 -15.249 -13.667  \n",
       "4    -19.661  -0.386  -3.601 -11.864  12.004 -4.735   2.717 -10.547 -16.252  \n",
       "...      ...     ...     ...     ...     ...    ...     ...     ...     ...  \n",
       "2510  10.001 -16.855  -5.087 -23.179   5.137  3.816  12.927  14.884  -4.688  \n",
       "2511  11.501 -13.710  -1.268 -20.021   1.492  5.614  17.683  16.285  -6.355  \n",
       "2512  12.052 -11.651   3.931 -16.441  -2.545  5.464  21.966  19.185  -8.814  \n",
       "2513  12.728 -12.196   9.347 -12.248  -5.109  3.308  24.553  23.874  -9.868  \n",
       "2514  14.003 -15.435  13.286  -7.952  -4.612  0.382  24.867  28.885  -8.586  \n",
       "\n",
       "[2515 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
    "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
    "        try:\n",
    "            data, atom_array, data_error_message=dataset[i]\n",
    "            target_id = data[\"sample_name\"]\n",
    "            assert target_id==test_df.target_id[i]\n",
    "            assert data_error_message==''\n",
    "            \n",
    "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "            runner.update_model_configs(new_configs)\n",
    "            prediction = runner.predict(data)\n",
    "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
    "\n",
    "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
    "        except:\n",
    "            target_id==test_df.target_id[i]\n",
    "            print('Failed to predict', target_id)\n",
    "            result=pd.DataFrame(columns=['ID', 'resname', 'resid', \n",
    "                                         'x_1', 'y_1', 'z_1', \n",
    "                                         'x_2', 'y_2', 'z_2',\n",
    "                                         'x_3', 'y_3', 'z_3', \n",
    "                                         'x_4', 'y_4', 'z_4', \n",
    "                                         'x_5', 'y_5', 'z_5'], \n",
    "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
    "            \n",
    "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
    "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    display(pd.read_csv('submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11553390,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6933267,
     "sourceId": 11118830,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 224830487,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2130.727261,
   "end_time": "2025-04-07T11:14:55.378160",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-07T10:39:24.650899",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
